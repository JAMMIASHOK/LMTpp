/*!
\tutorial Résoudre un système linéaire

    Résoudre un système linéaire est primordial pour de nombreux calculs. Il se fait généralement après linéarisation donc en bout de traitement mais il peut aussi se faire au début en calcul formel.
    
    Sur la plateforme LMT++, les calculs symboliques se font en général en Python dans les fichiers formulations ( 1ère partie ) et les calculs numériques en C++ ( 2è partie ).
    
        = Résolution formelle
    
            TODO
    
        = Résolution numérique
        
            La résolution dépend de plusieurs paramètres :
                * la dimension de la matrice
                * les propriétés de symétrie de la matrice
                * son type de stockage
                * si l'on souhaite calculer plusieurs systèmes avec la même matrice
              
            = Cas des matrices de petite dimension <= ~ 1000
            
                Le plus simple est de décomposer la matrice dans une structure qui gèrera le produit matrice-vecteur en utilisant la fonction <strong> inv() </strong>.
                Voici un exemple :
                \code C/C++
                    #include <containers/mat.h>
                    #include <containers/mat_true_inv.h>
                    #include <containers/matsparse.h>
                    using namespace std;
                    using namespace LMT;
                    
                    int main() {
                        typedef double T;
                        unsigned n = 10;
                        Vec<T> d, b, xth;

                        //srand ( time(NULL) );
                        
                        /// Matrice pleine
                        
                        d.resize( n * n );
                        for( unsigned i = 0; i < d.size(); ++i ) d[ i ] = rand()% 10 - 5;
                        xth.resize( n );
                        for( unsigned i = 0; i < xth.size(); ++i ) xth[ i ] = rand()% 10 - 5;
                        
                        Mat<T> A( n, n, d );    
                        b = A * xth;
                    
                        PRINTN( A ); PRINT( xth ); PRINT( b ); 
                        
                        Inv<T> iA = inv( A );
                        PRINT( iA * b );
                        
                        /// Matrice creuse
                        
                        cout << "***********" << endl;
                        
                        Mat< T, Gen<>, SparseLine<> > Asp;
                        
                        Asp.resize( n, n );
                        for( unsigned i = 0; i < n; ++i ) 
                            for( unsigned j = 0; j < n; ++j ) 
                            if ( ( rand() % 10 ) == 0 ) 
                                Asp( i, j ) = rand()% 10 - 5;
                        Asp.diag() = 10;
                        PRINTN( Asp ); 
                    
                        b = Asp * xth;
                    
                        Inv<T, Gen<>, SparseLine<> > iAsp = inv( Asp );
                        PRINT( iAsp * b );
                    
                        return 0;
                    } 
                    
                Remarque : la fonction <strong> inv() </strong> est spécialisée pour s'adapter automatiquement au type de la matrice du système ( e.g. pleine, creuse, symétrique ).
            
                Remarque : la fonction \a solve () encapsule le produit A^(-1) * b .
            
                on peut enfin calculer la matrice inverse par la fonction <strong> true_inv() </strong> puis faire le produit avec le second membre. C'est la méthode la plus coûteuse en temps de calcul.
                Exemple :
                \code C/C++
                    #include <containers/mat.h>
                    #include <containers/mat_true_inv.h>
                    using namespace std;
                    using namespace LMT;
                    
                    int main() {
                        unsigned n;
                        //srand ( time(NULL) );
                        Vec<double> d;
                        
                        n = 4;
                        
                        d.resize( n * n );
                        for( unsigned i = 0; i < d.size(); ++i ) d[ i ] = rand()% 10 -5;
                        Mat<double> A( n, n, d );
                        PRINTN( A ); 
                        
                        Mat<double> iA = true_inv( A );
                        PRINTN( iA * A ); /// identité à espilon ( i.e. ~ 1e-16 ) près
                        
                    
                        return 0;
                    }
                    
            = Cas des matrices de dimension moyenne ~ 10000
    
                = Matrice générale
                    
                    Si on doit résoudre plusieurs systèmes avec la même matrice, la décomposition <strong> LU </strong> s'impose. Sinon une méthode itérative peut être plus intéressante (voir le cas des matrices de grande dimension ci-dessous ).
                    De plus avec de telle dimension, les matrices sont généralement creuses. Nous ferons cette hypothèse pour ce paragraphe.
                    Pour la résolution de votre problème, il s'offre plusieurs choix :
                        * utiliser la sous-librairie <strong> UMFPACK </strong> ( paquet debian suitesparse ) . Elle est très rapide, stable numériquement. On la conseille par défaut.
                        * le code de la plateforme avec pivot partiel.
                        * le code de la plateforme sans pivot partiel. C'est un plus rapide que le précédent code mais on perd en stabilité numérique.
                          
                    Sur une machine Intel Core2 à 2.66 GHz, on obtient les résultats suivants pour une matrice asssez creuse de taille 2500 :  
                        * <strong> UMFPACK </strong>
                            erreur absolue -> 8.86035e-14
                            durée = 3.06 seconds
                        * avec pivot 
                            erreur absolue -> 3.892e-12
                            durée = 46.29 seconds
                        * sans pivot
                            erreur absolue -> 2.82353e-09
                            durée = 37.57 seconds
                    
                    Voici le code du test :
                    \code C/C++
                        #include <time.h> /// fonction clock()
    
                        #include <containers/mat.h>
                        #include <containers/matumfpack.h>
                        
                        using namespace std;
                        using namespace LMT;
                        
                        int main() {
                            typedef double T;          
                            unsigned n = 2500;
                            Vec<T> b, b2, b3, xth, x, x2, x3;
                            Vec<int> perm;
                            clock_t t1, t2;
                            double dt1, dt2, dt3;
                        
                            //srand ( time(NULL) );
                        
                            xth.resize( n );
                            for( unsigned i = 0; i < xth.size(); ++i ) xth[ i ] = rand()% 10 - 5;
                            
                            Mat< T, Gen<>, SparseLU > A, A2;
                            
                            A.resize( n );
                            
                            for( unsigned i = 0; i < n; ++i ) 
                                for( unsigned j = 0; j < n; ++j ) 
                                if ( ( rand() % 20 ) == 0 ) 
                                    A( i, j ) = rand() % 40 - 20;
                            A.diag() = 10;
                            A2 = A;
                            
                            Mat<double, Gen<>, SparseUMFPACK, void> A3( A );
                        
                            Mat< T > Agen = A; /// pour générer le vecteur b
                                
                            b = Agen * xth;
                            b2 = b;
                            b3 = b;
                            
                            /// LU sans pivot
                            t1  = clock(); 
                            lu_factorize( A );
                            t2  = clock();
                            dt1 = double( t2 - t1 ) / CLOCKS_PER_SEC;
                            
                            /// LU avec pivot
                            t1  = clock(); 
                            lu_factorize( A2, perm );
                            t2  = clock();
                            dt2 = double( t2 - t1 ) / CLOCKS_PER_SEC; 
                            
                            /// LU par UMFPACK 
                            t1  = clock(); 
                            A3.get_factorization();
                            t2  = clock();  
                            dt3 = double( t2 - t1 ) / CLOCKS_PER_SEC;
                        
                            solve_using_lu_factorize( A, b, x );
                            PRINT( max( abs( x - xth ) ) );
                            cout << "duration = " << dt1 << " seconds" << endl;
                                
                            solve_using_lu_factorize( A2, perm, b2, x2 );
                            PRINT( max( abs( x2 - xth ) ) );
                            cout << "duration = " << dt2 << " seconds" << endl;
                                                        
                            x3 = A3.solve( b3 );
                            PRINT( max( abs( x3 - xth ) ) );    
                            cout << "duration = " << dt3 << " seconds" << endl;
                                                        
                            return 0;
                        }

                    Pour compiler ce code il faut le lier à la sous-librairie <strong> UMFPACK </strong> , i.e. il faut ajouter les directives suivantes au compilateur :
                        *  <strong> -DWITH_UMFPACK </strong> ,
                        *  <strong> -lumfpack </strong> ,
                        *  <strong> -I/usr/include/suitesparse </strong> . 
                        
                    Dans un fichier SConstruct, cela donne :
                    \verbatim
                        CPPPATH = [ '#LMT/include' , '/usr/include/suitesparse' ],
                        LIBS = [ 'pthread', 'cholmod' , 'umfpack' ],
                        CPPFLAGS = cppflags( ['xml2-config'] ) + " -g3 -O3 " + " -DWITH_UMFPACK " ,
                    
                    Remarques :
                    La classe \a Mat<double,Gen<>,SparseUMFPACK,void> encapsule le code de la <strong> UMFPACK </strong> .
                    Pour le code de la plateforme, on se sert des matrices du type \a Mat<T,Gen<>,SparseLU> qui sont adaptées.
                    Pour la décomposition on utilise la méthode <strong> get_factorization() </strong> de \a Mat<double,Gen<>,SparseUMFPACK,void> et, pour le code de la plateforme, les fonctions <strong> lu_factorize(  Mat < T , Gen < > , SparseLU > &  m ) </strong> et <strong> lu_factorize( Mat<T,Gen<>,SparseLU> &m, Vec<int> &vector_permutation ) </strong> qui stocke dans m le résultat de la décomposition. La matrice m initiale est donc effacée. Enfin la deuxième <strong> lu_factorize() </strong> renvoie aussi le vecteur permutation des lignes lors des changements de pivots.
                    Ensuite pour résoudre le système, on se sert de  la fonction <strong>  solve_using_lu_factorize() </strong> ou la méthode <strong> solve( ) </strong> de \a Mat<double,Gen<>,SparseUMFPACK,void> .
 
                
                = Matrice symétrique
    
                    Pour de tels systèmes, il est possible d'utiliser la librairie de Timothy A Davis qui réalise une décomposition LDL ( valable seulement pour les matrices creuses ) ou réaliser une décomposition de Cholesky avec la fonction <strong> solve_using_chol_factorize() </strong> .
                    Comme la décomposition LDL est dans la pratique plus robuste que la décomposition de Cholesky, on la présente en premier. 
                    De plus la décomposition LDL s'applique à toutes les matrices symétriques.
                    Rappelons que la librairie de Timothy s'applique surtout aux matrices creuses.  
                    
                    = Décomposition LDL
                    
                        La classe \a LDL_solver encapsule le code de Tim et mémorise les options de la résolution.
                        REMARQUE TRES IMPORTANTE : la méthode <strong> get_factorization() </strong> EFFACE la matrice passée en paramètre avec les paramètres par défaut!
                        
                        voici un exemple d'utilisation :
                        \code C/C++
                            #include <containers/mat.h>
                            #include <util/solveLDL.h>
                            using namespace std;
                            using namespace LMT;
                            
                            int main() {
                                typedef double T;
                                unsigned n = 10;
                                Vec<T> b, xth;

                                //srand ( time(NULL) );
                            
                                xth.resize( n );
                                for( unsigned i = 0; i < xth.size(); ++i ) xth[ i ] = rand()% 10 - 5;
                                
                                Mat< T, Sym<>, SparseLine<> > Asp;
                                
                                Asp.resize( n );
                                
                                for( unsigned i = 0; i < n; ++i ) 
                                    for( unsigned j = 0; j <= i; ++j ) 
                                    if ( ( rand() % 10 ) == 0 ) 
                                        Asp( i, j ) = rand()% 10 - 5;
                                Asp.diag() = 10;
                                
                                PRINTN( Asp ); PRINT( xth );
                            
                                b = Asp * xth;
                            
                                LDL_solver ldl;
                                
                                ldl.get_factorization( Asp );
                                
                                ldl.solve( b );
                                
                                PRINT( b );
                                
                                return 0;
                            }
                            
                        Les méthodes get_factorization() ont les arguments <strong> want_free </strong> , <strong> want_semi_morse </strong> et <strong> want_amd_order </strong> :
                            * <strong> want_free </strong> : s'il est mis à vrai (valeur par défaut), la méthode libère la mémoire de la matrice <strong> mat </strong> passée en argument sinon mat reste inchangée.
                            * <strong> want_semi_morse </strong> : paramètre de l'algoritme de factorisation  ( TODO ) ?????
                            * <strong> want_amd_order </strong> : paramètre de l'algoritme de factorisation ( TODO ) ?????
                        Ce sont elles qui effectuent la factorisation LDL.
                        Ensuite pour résoudre le système Ax = b, on appelle la méthode <strong> solve( b ) </strong> qui efface la valeur de b et la remplace par la solution A^(-1) * b.
                        
                    = Décomposition de Cholesky avec le code de la plate-forme
                
                        On utilise les fonctions <strong> chol_factorize() </strong> et <strong> solve_using_chol_factorize() </strong> qui respectivement décompose la matrice et résout un système linéaire.
                        IMPORTANT : il FAUT avoir DECOMPOSER la matrice avant d'utiliser <strong> solve_using_chol_factorize() </strong> !
                        IMPORTANT : la matrice passée en paramètre de <strong> chol_factorize() </strong> est MODIFIEE !
                        Exemple :
                        \code C/C++
                            #include <containers/mat.h>
                            using namespace std;
                            using namespace LMT;
                            
                            int main() {
                            
                                Mat<double,Sym<>,SparseLine<> > m(3);
                                m.diag() = 130.;
                                m(0,1) = 30.;
                                m(0,2) = 1.;
                                Mat<double,Sym<>,SparseLine<> > msa = m;
                                PRINTN( msa );
                                        // msa ->
                                        // 130 30  1
                                        // 30  130 0
                                        // 1   0   130
                                chol_factorize( m );
                                Vec<double> f( -45, 40, -1 );
                                PRINTN( f );
                                        // f ->
                                        // -45 40 -1
                                Vec<double> x;
                                solve_using_chol_factorize( m, f, x );
                                PRINTN( x );
                                        //  x ->
                                        //  -0.44059 0.409367 -0.00430315
                                PRINTN( msa * x - f );
                                        //  msa * x - f ->
                                        //  -7.10543e-15 7.10543e-15 0
                                
                                return 0;
                            }
                                
                    = Décomposition de Cholesky avec la librairie CHOLMOD
                    
                        On se sert de la classe \a Mat<double,Sym<>,SparseCholMod,void> qui est une matrice particulière proposant les méthodes <strong> get_factorization() </strong> et <strong> solve() </strong> pour la résolution de systèmes linéaires.
                        Elle encapsule les fonctions de la librairie CholMod de Timothy A Davis.
                        Son utilisation standard est :
                        \code C/C++
                            Mat< T, Sym<>, SparseLine<> > A;
                            Mat<double, Sym<>, SparseCholMod, void> A2( A );
                    
                            bool successful = A2.get_factorization();
                            Vec<T> x = A2.solve( b );
                    
                        La matrice <strong> A </strong> sert surtout pour construire facilement une matrice creuse.
                        La deuxième ligne permet de lier A dans A2.
                        La méthode <strong> get_factorization() </strong> factorise ou du moins si elle n'y arrive pas elle renvoie faux.
                        La méthode <strong> solve() </strong> résout à condition bien sûr que la factorisation se soit bien passée ;-)
                        
                        Voici un exemple de code qui rassemble les trois méthodes et fournit aussi un petit benchmark :
                        Remarque : il faut absolument COMPILER le code avec la DIRECTIVE <strong> -DWITH_CHOLMOD </strong> et la librairie cholmod ( i.e. option <strong> -lcholmod </strong> .
                         
                        \code C/C++
                            #include <time.h> /// fonction clock()

                            #include <containers/mat.h>
                            #include <util/solveLDL.h>
                            #include <containers/matcholamd.h>
                            
                            using namespace std;
                            using namespace LMT;
                            
                            
                            int main() {
                                typedef double T;          
                                unsigned n = 5000;
                                Vec<T> b, xth, x, x2, x3;
                                clock_t t1, t2;
                                double dt1, dt2, dt3;
                            
                                //srand ( time(NULL) );
                            
                                /// solution exacte
                                xth.resize( n );
                                for( unsigned i = 0; i < xth.size(); ++i ) xth[ i ] = rand()% 10 - 5;
                                //PRINT( xth );
                                
                                Mat< T, Sym<>, SparseLine<> > A, A3;
                                
                                A.resize( n );
                                
                                for( unsigned i = 0; i < n; ++i ) 
                                    for( unsigned j = 0; j <= i; ++j ) 
                                    if ( ( rand() % 90 ) == 0 ) 
                                        A( i, j ) = rand() % 40 - 20;
                                A.diag() = 40 + 5 * n;
                                //PRINTN( A );
                                A3 = A;
                                
                                Mat<double, Sym<>, SparseCholMod, void> A2( A );
                            
                                /// on génére le vecteur b du système Ax = b
                                b = A * xth;
                                //PRINT( b );
                                
                                /// Cholesky de la plate-forme
                                t1  = clock();
                                chol_factorize( A3 ); 
                                t2  = clock();
                                dt1 = double( t2 - t1 ) / CLOCKS_PER_SEC;
                                
                                /// CholMod de Timothy
                                t1  = clock(); 
                                bool successful = A2.get_factorization();
                                t2  = clock();  
                                dt2 = double( t2 - t1 ) / CLOCKS_PER_SEC;
                                PRINT( successful );
                            
                                /// LDL de Timothy
                                LDL_solver ldl;
                                t1  = clock();
                                ldl.get_factorization( A, false, false, true );
                                t2  = clock();  
                                dt3 = double( t2 - t1 ) / CLOCKS_PER_SEC;
                                
                                solve_using_chol_factorize( A3, b, x );
                                cout << "== Implementation de Cholesky dans la plate-forme" << endl;
                                cout << "absolute error = " << max( abs( x - xth ) ) << endl;
                                cout << "duration = " << dt1 << " seconds" << endl;
                                                            
                                x2 = A2.solve( b );
                                cout << "== CholMod de Timothy" << endl;
                                cout << "absolute error = " << max( abs( x2 - xth ) ) << endl;
                                cout << "duration = " << dt2 << " seconds" << endl;
                                                            
                                x3 = b; 
                                ldl.solve( x3 );
                                cout << "== LDL de Timothy" << endl;
                                cout << "absolute error = " << max( abs( x3 - xth ) ) << endl;
                                cout << "duration = " << dt3 << " seconds" << endl;
                                                        
                                cout << endl;
                                cout << " plate-forme / CholMod = " << dt1 / dt2 << endl;
                                cout << " LDL / CholMod = " << dt3 / dt2 << endl;
                                
                                return 0;
                            }
                        
                        Le résultat sur mon brave core2  à 2.66 GHz est :
                        \verbatim     
                            successful -> 1
                            == Implementation de Cholesky dans la plate-forme
                            absolute error = 3.90799e-14
                            duration = 138.41 seconds
                            == CholMod de Timothy
                            absolute error = 1.11022e-14
                            duration = 7.3 seconds
                            == LDL de Timothy
                            absolute error = 4.9738e-14
                            duration = 94.79 seconds

                            plate-forme / CholMod = 18.9603
                            LDL / CholMod = 12.9849

      
                        Sur cet exemple, on constate que la stabilité numérique est semblable pour les trois méthodes. En terme de vitesse, CholMod sort du peloton.
                                
            = Cas des matrices de grande dimension ~ 1000000 ou plus

                = Matrice générale
                    
                    On peut essayer la décomposition <strong> LU </strong> ... 
                    Bonne chance ! 
                
                = Matrice symétrique

                    Dans le cas de matrices symétriques définies positives, en place de la méthode de Cholesky, on peut se servir de la méthode du <strong> gradient conjugué </strong> qui certes requiert plus de calculs mais seulement des produits matrice-vecteur. Or pour les problèmes éléments finis, les matrices sont parfois de grande taille mais creuses et donc effectuer seulement de tels produits permet de ne pas stocker la matrice et de plus ils demandent bien moins d'opérations que les produits matrice-vecteur standards. 
                    
                    Voici la signature de la fonction <strong>
                    conjugate_gradient( const Precond &, const Matrix &, const Sollicitation &, SOLUTION &, const CritOperator & ) </strong> qu'on utilise.

                        * Le type <strong> Precond </strong> sert de pré-conditionneur. Actuellement il y en a deux dans la plateforme \a SolveUsingCholFactorize et \a SolveUsingCholMod . Leur unique constructeur prend en paramètre une matrice ( creuse ) celle du système à résoudre et une instance de ces types gardera une référence à cette matrice creuse. Ensuite le pré-conditionneur doit fournir un produit à droite avec un vecteur. Les deux classes précédentes se distinguent à ce niveau car la première utilise la fonction <strong> solve_using_chol_factorize() </strong> et la seconde utilise la méthode <strong> solve() </strong> de la matrice passée en paramètre. Enfin on peut utiliser les fonctions <strong> new_SolveUsingCholFactorize() </strong> et <strong> new_SolveUsingCholMod() </strong> pour créer une instance de ces pré-conditionneurs.
                        * Le type <strong> Matrice </strong> est le type de la matrice du système i.e. Mat< T,Sym<>,SparseLine<> > où T est de type scalaire ( e.g. double ou float ).
                        * Les types <strong> Sollicitation </strong> et <strong> SOLUTION </strong> sont des vecteurs de scalaires de même taille.
                        * Le type <strong> CritOperator </strong> est un  type qui contient le type de mesure d'erreur avec ces éventuels paramètres. Un exemple est \a ConvergenceCriteriumNormInfDelta  et pour créer un tel objet, on écrirait :
                        \code C/C++
                            ConvergenceCriteriumNormInfDelta<double> critere( 1e-5 );
                    
                    Cette fonction renvoie le nombre d'iérations nécessaires à la résolution.
                    
                    Exemple :
                    \code C/C++
                        #include <containers/mat.h>
                        #include <containers/conjugate_gradient.h>
                        using namespace std;
                        using namespace LMT;
                        
                        int main() {
                            typedef double T;
                            unsigned n = 400;
                            Vec<T> b, xth, x;
                        
                            //srand ( time(NULL) );
                        
                            xth.resize( n );
                            for( unsigned i = 0; i < xth.size(); ++i ) xth[ i ] = rand()% 10 - 5;
                            
                            Mat< T, Sym<>, SparseLine<> > Asp;
                            
                            Asp.resize( n );
                            
                            for( unsigned i = 0; i < n; ++i ) 
                                for( unsigned j = 0; j <= i; ++j ) 
                                if ( ( rand() % 20 ) == 0 ) 
                                    Asp( i, j ) = rand() % 10 - 5;
                            Asp.diag() = 10;
                            
                            //PRINTN( Asp );
                            
                            incomplete_chol_factorize( Asp ); 
                            
                            //PRINTN( Asp ); PRINT( xth );
                        
                            b = Asp * xth;
                            
                            unsigned cpt_iter = conjugate_gradient( new_SolveUsingCholFactorize( Asp ), Asp, b, x, ConvergenceCriteriumNormInfDelta<double>( 1e-14 ) );
                            
                            PRINT( max( abs( x - xth ) ) );
                            PRINT( cpt_iter );
                            
                            return 0;
                        }

*/


