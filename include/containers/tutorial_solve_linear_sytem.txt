/*!
\tutorial Résoudre un système linéaire

    Résoudre un système linéaire est primordial pour de nombreux calculs. Il se fait généralement après linéarisation donc en bout de traitement mais il peut aussi se faire au début en calcul formel.
    
    Sur la plateforme LMT++, les calculs symboliques se font en général en Python dans les fichiers formulations ( 1ère partie ) et les calculs numériques en C++ ( 2è partie ).
    
        = Résolution formelle
    
            TODO
    
        = Résolution numérique
        
            La résolution dépend de plusieurs paramètres :
                * la dimension de la matrice
                * les propriétés de symétrie de la matrice
                * son type de stockage
                * si l'on souhaite calculer plusieurs systèmes avec la même matrice
              
            = Cas des matrices de petite dimension <= ~ 50
            
                Le plus simple est de décomposer la matrice dans une structure qui gèrera le produit matrice-vecteur en utilisant la fonction <strong> inv() </strong>.
                Voici un exemple :
                \code C/C++
                    #include <containers/mat.h>
                    #include <containers/mat_true_inv.h>
                    #include <containers/matsparse.h>
                    using namespace std;
                    using namespace LMT;
                    
                    int main() {
                        typedef double T;
                        unsigned n = 10;
                        Vec<T> d, b, xth;

                        //srand ( time(NULL) );
                        
                        /// Matrice pleine
                        
                        d.resize( n * n );
                        for( unsigned i = 0; i < d.size(); ++i ) d[ i ] = rand()% 10 - 5;
                        xth.resize( n );
                        for( unsigned i = 0; i < xth.size(); ++i ) xth[ i ] = rand()% 10 - 5;
                        
                        Mat<T> A( n, n, d );    
                        b = A * xth;
                    
                        PRINTN( A ); PRINT( xth ); PRINT( b ); 
                        
                        Inv<T> iA = inv( A );
                        PRINT( iA * b );
                        
                        /// Matrice creuse
                        
                        cout << "***********" << endl;
                        
                        Mat< T, Gen<>, SparseLine<> > Asp;
                        
                        Asp.resize( n, n );
                        for( unsigned i = 0; i < n; ++i ) 
                            for( unsigned j = 0; j < n; ++j ) 
                            if ( ( rand() % 10 ) == 0 ) 
                                Asp( i, j ) = rand()% 10 - 5;
                        Asp.diag() = 10;
                        PRINTN( Asp ); 
                    
                        b = Asp * xth;
                    
                        Inv<T, Gen<>, SparseLine<> > iAsp = inv( Asp );
                        PRINT( iAsp * b );
                    
                        return 0;
                    } 
                    
                Remarque : la fonction <strong> inv() </strong> est spécialisée pour s'adapter automatiquement au type de la matrice du système ( e.g. pleine, creuse, symétrique ).
            
                Remarque : la fonction \a solve () encapsule le produit A^(-1) * b .
            
                on peut enfin calculer la matrice inverse par la fonction <strong> true_inv() </strong> puis faire le produit avec le second membre. C'est la méthode la plus coûteuse en temps de calcul.
                Exemple :
                \code C/C++
                    #include <containers/mat.h>
                    #include <containers/mat_true_inv.h>
                    using namespace std;
                    using namespace LMT;
                    
                    int main() {
                        unsigned n;
                        //srand ( time(NULL) );
                        Vec<double> d;
                        
                        n = 4;
                        
                        d.resize( n * n );
                        for( unsigned i = 0; i < d.size(); ++i ) d[ i ] = rand()% 10 -5;
                        Mat<double> A( n, n, d );
                        PRINTN( A ); 
                        
                        Mat<double> iA = true_inv( A );
                        PRINTN( iA * A ); /// identité à espilon ( i.e. ~ 1e-16 ) près
                        
                    
                        return 0;
                    }
                    
            = Cas des matrices de dimension moyenne ~ 10000
    
                = Matrice générale
                    
                    Sous l'hypothèse que l'on doit résoudre des systèmes avec la même matrice, on réalise une décomposition <strong> LU </strong> avec ou sans pivot partiel. Le pivot partiel demande un plus de calcul mais on gagne en stabilité numrique.
                    Vu la taille des matrices, on fait aussi l'hypothèse qu ' elles sont creuses. Alors on se sert des matrices du type \a Mat<T,Gen<>,SparseLU> qui sont adaptées.
                    Pour la décomposition on utilise les fonctions <strong> lu_factorize(  Mat < T , Gen < > , SparseLU > &  m ) </strong> et <strong> lu_factorize( Mat<T,Gen<>,SparseLU> &m, Vec<int> &vector_permutation ) </strong> qui stocke dans m le résultat de la décomposition. La matrice m initiale est donc effacée. Enfin la deuxième <strong> lu_factorize() </strong> renvoie aussi le vecteur permutation des lignes
lors des changements de pivots.
                    Ensuite pour résoudre le système, on se sert de  la fonction <strong>  solve_using_lu_factorize() </strong> .
                    
                    Voici un exemple de code qui utilise les deux fonctions ( avec ou sans pivot partiel ) :
                    \code C/C++
                        #include <containers/mat.h>

                        using namespace std;
                        using namespace LMT;
                        
                        int main() {
                            typedef double T;
                            unsigned n = 1000;
                            Vec<T> b, b2, xth, x, x2;
                            Vec<int> perm;
                        
                            //srand ( time(NULL) );
                        
                            xth.resize( n );
                            for( unsigned i = 0; i < xth.size(); ++i ) xth[ i ] = rand()% 10 - 5;
                            
                            Mat< T, Gen<>, SparseLU > A, A2;
                            
                            A.resize( n );
                            
                            for( unsigned i = 0; i < n; ++i ) 
                                for( unsigned j = 0; j < n; ++j ) 
                                if ( ( rand() % 20 ) == 0 ) 
                                    A( i, j ) = rand() % 40 - 20;
                            A.diag() = 10;
                            A2 = A;
                            
                            //PRINTN( A );
                            Mat< T > Agen = A; /// pour 
                                
                            //PRINT( xth );
                        
                            b = Agen * xth;
                            b2 = b;
                            
                            lu_factorize( A );
                            lu_factorize( A2, perm );
                        
                            solve_using_lu_factorize( A, b, x );
                            PRINT( max( abs( x - xth ) ) );
                                
                            solve_using_lu_factorize( A2, perm, b2, x2 );
                            PRINT( max( abs( x2 - xth ) ) );
                                
                            return 0;
                        }
                
                = Matrice symétrique
    
                    Pour de tels systèmes, il est possible d'utiliser la librairie de Timothy A Davis qui réalise une décomposition LDL ( valable seulement pour les matrices creuses ) ou réaliser une décomposition de Cholesky avec la fonction <strong> solve_using_chol_factorize() </strong> .
                    Comme la décomposition LDL est dans la pratique plus robuste que la décomposition de Cholesky, on la présente en premier. Rappelons que la librairie de Timothy s'applique seulement aux matrices creuses.   
                    
                    = Décomposition LDL
                    
                        La classe \a LDL_solver encapsule le code de Tim et mémorise les options de la résolution.
                        voici un exemple d'utilisation :
                        \code C/C++
                            #include <containers/mat.h>
                            #include <util/solveLDL.h>
                            using namespace std;
                            using namespace LMT;
                            
                            int main() {
                                typedef double T;
                                unsigned n = 10;
                                Vec<T> b, xth;

                                //srand ( time(NULL) );
                            
                                xth.resize( n );
                                for( unsigned i = 0; i < xth.size(); ++i ) xth[ i ] = rand()% 10 - 5;
                                
                                Mat< T, Sym<>, SparseLine<> > Asp;
                                
                                Asp.resize( n );
                                
                                for( unsigned i = 0; i < n; ++i ) 
                                    for( unsigned j = 0; j <= i; ++j ) 
                                    if ( ( rand() % 10 ) == 0 ) 
                                        Asp( i, j ) = rand()% 10 - 5;
                                Asp.diag() = 10;
                                
                                PRINTN( Asp ); PRINT( xth );
                            
                                b = Asp * xth;
                            
                                LDL_solver ldl;
                                
                                ldl.get_factorization( Asp );
                                
                                ldl.solve( b );
                                
                                PRINT( b );
                                
                                return 0;
                            }
                            
                        Les méthodes get_factorization() ont les arguments <strong> want_free </strong> , <strong> want_semi_morse </strong> et <strong> want_amd_order </strong> :
                            * <strong> want_free </strong> : s'il est mis à vrai (valeur par défaut), la méthode libère la mémoire de la matrice <strong> mat </strong> passée en argument sinon mat reste inchangée.
                            * <strong> want_semi_morse </strong> : paramètre de l'algoritme de factorisation  ?????
                            * <strong> want_amd_order </strong> : paramètre de l'algoritme de factorisation ?????
                        Ce sont elles qui effectuent la factorisation LDL.
                        Ensuite pour résoudre le système Ax = b, on appelle la méthode <strong> solve( b ) </strong> qui efface la valeur de b et la remplace par la solution A^(-1) * b.
                        
                    = Décomposition de Cholesky
                
                        On utilise les fonctions <strong> chol_factorize() </strong> et <strong> solve_using_chol_factorize() </strong> qui respectivement décompose la matrice et résout un système linéaire.
                        IMPORTANT : il FAUT avoir DECOMPOSER la matrice avant d'utiliser <strong> solve_using_chol_factorize() </strong> !
                        Exemple :
                        \code C/C++
                            #include <containers/mat.h>
                            using namespace std;
                            using namespace LMT;
                            
                            int main() {
                            
                                Mat<double,Sym<>,SparseLine<> > m(3);
                                m.diag() = 130.;
                                m(0,1) = 30.;
                                m(0,2) = 1.;
                                Mat<double,Sym<>,SparseLine<> > msa = m;
                                PRINTN( msa );
                                        // msa ->
                                        // 130 30  1
                                        // 30  130 0
                                        // 1   0   130
                                chol_factorize( m );
                                Vec<double> f( -45, 40, -1 );
                                PRINTN( f );
                                        // f ->
                                        // -45 40 -1
                                Vec<double> x;
                                solve_using_chol_factorize( m, f, x );
                                PRINTN( x );
                                        //  x ->
                                        //  -0.44059 0.409367 -0.00430315
                                PRINTN( msa * x - f );
                                        //  msa * x - f ->
                                        //  -7.10543e-15 7.10543e-15 0
                                
                                return 0;
                            }
                                
            = Cas des matrices de grande dimension ~ 1000000 ou plus

                = Matrice générale
                    
                    On peut essayer la décomposition <strong> LU </strong> ... 
                    Bonne chance ! 
                
                = Matrice symétrique

                    Dans le cas de matrices symétriques définies positives, en place de la méthode de Cholesky, on peut se servir de la méthode du <strong> gradient conjugué </strong> qui certes requiert plus de calculs mais seulement des produits matrice-vecteur. Or pour les problèmes éléments finis, les matrices sont parfois de grande taille mais creuses et donc effectuer seulement de tels produits permet de ne pas stocker la matrice et de plus ils demandent bien moins d'opérations que les produits matrice-vecteur standards. 
                    
                    Voici la signature de la fonction <strong>
                    conjugate_gradient( const Precond &, const Matrix &, const Sollicitation &, SOLUTION &, const CritOperator & ) </strong> qu'on utilise.

                        * Le type <strong> Precond </strong> sert de pré-conditionneur. Actuellement il y en a deux dans la plateforme \a SolveUsingCholFactorize et \a SolveUsingCholMod . Leur unique constructeur prend en paramètre une matrice ( creuse ) celle du système à résoudre et une instance de ces types gardera une référence à cette matrice creuse. Ensuite le pré-conditionneur doit fournir un produit à droite avec un vecteur. Les deux classes précédentes se distinguent à ce niveau car la première utilise la fonction <strong> solve_using_chol_factorize() </strong> et la seconde utilise la méthode <strong> solve() </strong> de la matrice passée en paramètre. Enfin on peut utiliser les fonctions <strong> new_SolveUsingCholFactorize() </strong> et <strong> new_SolveUsingCholMod() </strong> pour créer une instance de ces pré-conditionneurs.
                        * Le type <strong> Matrice </strong> est le type de la matrice du système i.e. Mat< T,Sym<>,SparseLine<> > où T est de type scalaire ( e.g. double ou float ).
                        * Les types <strong> Sollicitation </strong> et <strong> SOLUTION </strong> sont des vecteurs de scalaires de même taille.
                        * Le type <strong> CritOperator </strong> est un  type qui contient le type de mesure d'erreur avec ces éventuels paramètres. Un exemple est \a ConvergenceCriteriumNormInfDelta  et pour créer un tel objet, on écrirait :
                        \code C/C++
                            ConvergenceCriteriumNormInfDelta<double> critere( 1e-5 );
                    
                    Cette fonction renvoie le nombre d'iérations nécessaires à la résolution.
                    
                    Exemple :
                    \code C/C++
                        #include <containers/mat.h>
                        #include <containers/conjugate_gradient.h>
                        using namespace std;
                        using namespace LMT;
                        
                        int main() {
                            typedef double T;
                            unsigned n = 400;
                            Vec<T> b, xth, x;
                        
                            //srand ( time(NULL) );
                        
                            xth.resize( n );
                            for( unsigned i = 0; i < xth.size(); ++i ) xth[ i ] = rand()% 10 - 5;
                            
                            Mat< T, Sym<>, SparseLine<> > Asp;
                            
                            Asp.resize( n );
                            
                            for( unsigned i = 0; i < n; ++i ) 
                                for( unsigned j = 0; j <= i; ++j ) 
                                if ( ( rand() % 20 ) == 0 ) 
                                    Asp( i, j ) = rand() % 10 - 5;
                            Asp.diag() = 10;
                            
                            //PRINTN( Asp );
                            
                            incomplete_chol_factorize( Asp ); 
                            
                            //PRINTN( Asp ); PRINT( xth );
                        
                            b = Asp * xth;
                            
                            unsigned cpt_iter = conjugate_gradient( new_SolveUsingCholFactorize( Asp ), Asp, b, x, ConvergenceCriteriumNormInfDelta<double>( 1e-14 ) );
                            
                            PRINT( max( abs( x - xth ) ) );
                            PRINT( cpt_iter );
                            
                            return 0;
                        }

*/


